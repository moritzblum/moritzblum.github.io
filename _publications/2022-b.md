---
title: "Exploring the impact of literal transformations within Knowledge Graphs for Link Prediction"
collection: publications
permalink: /publication/2022-b
excerpt: 'This paper is about transforming attributive triples into relational triples for Link Prediction.'
date: 2022-10-28
venue: 'IJCKG 22'
paperurl: 'https://dl.acm.org/doi/abs/10.1145/3579051.3579069'
citation: 'Blum M, Ell B, Cimiano P. Exploring the impact of literal transformations within Knowledge Graphs for Link Prediction. In: Artale A, Calvanese D, Wang H, Zhang X, eds. IJCKG 22: Proceedings of the 11th International Joint Conference on Knowledge Graphs. ACM Other Conferences. New York, NY: ACM; 2022: 48-54.'
---
Knowledge Graphs are relevant for many applications, but are inherently incomplete. 
Thus, Link Prediction methods have been proposed to infer new triples in order to complete a given Knowledge Graph. 
Many Link Prediction methods ignore literals, in spite of the fact that literals can express important information 
about entities not encoded in relations between entities. 
The existing methods that do incorporate literal information (e. g., LiteralE) introduce complex architectures 
by modifying the model or the loss-function. In our research paper, we propose a new approach that relies on graph 
transformations to transform a graph in such a way that existing Link Prediction methods can leverage the 
literal information. In particular, we define three transformations and evaluate them in comparison to 
state-of-the-art approaches. In most cases, the additional triples generated by our transformations lead to a 
performance increase and even state-of-the-art performance can be reached when comparing against LiteralE. 
It turned out that even a reductionistic transformation is able to archive comparable results like current, 
more complex, state-of-the-art approaches which incorporate literals.
